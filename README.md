Pour ce projet on m'a chargé de prédire les émissions de CO2 et la consommation totale d'énergie de bâtiments dans la ville de Seattle, ainsi que d'évaluer l'intérêt de l'ENERGYSTARScore. Les prédictions se basent sur des relevés effectués par des agents de la ville, ainsi que les données structurelles des bâtiments (taille et usage des bâtiments, date de construction, situation géographique, ...). On m'a demandé de rendre trois notebooks séparément, le premier concerne le nettoyage des données et l'analyse exploratoire (ainsi que du feature engineering un peu plus poussé que dans le projet précédent), les deux suivants concernent les prédictions : la consommation d'énergie et les émissions de CO2 respectivement. Dans chacun de ces deux notebooks, je teste différents encoders pour les variables qualitatives : OneHot, Binary et Target. J'effectue un passage au log sur les targets afin de réduire les valeurs extrêmes et d'aboutir à une distribution plus proche de la distribution normale. Je teste ensuite différents modèles : DummyRegressor, Ridge, Lasso, ElasticNet, DecisionTree, SVR, KernelRidge, RandomForestRegressor et XGBRegressor ; sur différentes métriques : MAE, MSE, RMSE, R². D'abord sans toucher aux hyperparamètres, seulement pour tester chacun des encoders et conserver celui qui se démarque le plus. Ensuite j'ai fait une validation croisée pour affiner les hyperparamètres de chaque modèle tout en évitant l'overfitting en utilisant soit GridSearchCV (lors que c'était assez rapide), soit une combinaison de RandomizedSearchCV (afin de balayer large) et GridSearchCV (pour affiner la recherche). Dans chaque cas, je fais un residplot pour visualiser l'homo ou hétéroscédasticité des résidus. Suite à cela, j'entraîne le modèle présentant les meilleurs résultats, procède à une analyse de feature importance globale, d'abord sans et ensuite avec la feature ENERGYSTARScore afin de mesurer son impact sur chaque target.
